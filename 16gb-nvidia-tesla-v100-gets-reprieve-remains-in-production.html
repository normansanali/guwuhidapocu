<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=description content="Back in March at their annual GPU Technology Conference, NVIDIA announced the long-anticipated 32GB version of their flagship Tesla V100 accelerator. By using newer 8-Hi HBM2 memory stacks, NVIDIA was able to double the accelerators previous 16GB of VRAM to a class-leading 32GB. Meanwhile, at the time company representatives told us that the launch of"><meta name=author content="Reinaldo Massengill"><meta name=generator content="Hugo 0.98.0"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=robots content="index,follow,noarchive"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/base16/css/style.css type=text/css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700" type=text/css><link rel=alternate href=./index.xml type=application/rss+xml title=BlinkVib><title>16GB NVIDIA Tesla V100 Gets Reprieve; Remains in Production - BlinkVib</title></head><body><header><div class="container clearfix"><a class=path href=./index.html>[BlinkVib]</a>
<span class=caret># _</span><div class=right></div></div></header><div class=container><main role=main class=article><article class=single itemscope itemtype=http://schema.org/BlogPosting><div class=meta><span class=key>published on</span>
<span class=val><time itemprop=datePublished datetime=2024-08-28>August 28, 2024</time></span>
<span class=key>in</span>
<span class=val><a href=./categories/blog>blog</a></span></div><h1 class=headline itemprop=headline>16GB NVIDIA Tesla V100 Gets Reprieve; Remains in Production</h1><section class=body itemprop=articleBody><img src=https://cdn.statically.io/img/images.anandtech.com/doci/12809/v100board_678x452.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><p>Back in March at their annual GPU Technology Conference, <a href=#>NVIDIA announced the long-anticipated 32GB version of their flagship Tesla V100 accelerator</a>. By using newer 8-Hi HBM2 memory stacks, NVIDIA was able to double the accelerator’s previous 16GB of VRAM to a class-leading 32GB. Meanwhile, at the time company representatives told us that the launch of the 32GB model would be a wholesale replacement of the 16GB model, with the smaller version to be phased out and all future cards to go out as the 32GB model.</p><p>However, this week NVIDIA has reached out to inform us that this will not the case, and that the 16GB model is being continued after all.</p><p>In a somewhat odd exchange, the official line from the company is that the previous statement – made in the heat of a pre-briefing Q&A session – was in error, and that the 16GB model was never being discontinued. Instead, NVIDIA’s plan has always been to sell the two models side-by-side. Unfortunately, the company hasn’t been able to make it clear why that information wasn’t presented at the show instead; though what I do know is that this wasn’t caught until customers recently started asking questions.</p><table align=center border=0 cellpadding=0 cellspacing=1 width=650><tbody readability=2><tr class=tgrey readability=2><td align=center colspan=7>NVIDIA Tesla/Titan Family Specification Comparison</td></tr><tr class=tlblue><td width=140>&nbsp;</td><td align=center valign=middle width=126>Tesla V100<br>(SXM2)</td><td align=center valign=middle width=126>Tesla V100<br>(PCIe)</td><td align=center valign=middle width=126>Titan V<br>(PCIe)</td><td align=center valign=middle width=126>Tesla P100<br>(SXM2)</td></tr><tr><td class=tlgrey>CUDA Cores</td><td align=center valign=middle>5120</td><td align=center valign=middle>5120</td><td align=center valign=middle>5120</td><td align=center valign=middle>3584</td></tr><tr><td class=tlgrey>Tensor Cores</td><td align=center valign=middle>640</td><td align=center valign=middle>640</td><td align=center valign=middle>640</td><td align=center valign=middle>N/A</td></tr><tr><td class=tlgrey>Core Clock</td><td align=center valign=middle>?</td><td align=center valign=middle>?</td><td align=center valign=middle>1200MHz</td><td align=center valign=middle>1328MHz</td></tr><tr><td class=tlgrey>Boost Clock</td><td align=center valign=middle>1455MHz</td><td align=center valign=middle>1370MHz</td><td align=center valign=middle>1455MHz</td><td align=center valign=middle>1480MHz</td></tr><tr><td class=tlgrey>Memory Clock</td><td align=center valign=middle>1.75Gbps HBM2</td><td align=center valign=middle>1.75Gbps HBM2</td><td align=center valign=middle>1.7Gbps HBM2</td><td align=center valign=middle>1.4Gbps HBM2</td></tr><tr><td class=tlgrey>Memory Bus Width</td><td align=center valign=middle>4096-bit</td><td align=center valign=middle>4096-bit</td><td align=center valign=middle>3072-bit</td><td align=center valign=middle>4096-bit</td></tr><tr><td class=tlgrey>Memory Bandwidth</td><td align=center valign=middle>900GB/sec</td><td align=center valign=middle>900GB/sec</td><td align=center valign=middle>653GB/sec</td><td align=center valign=middle>720GB/sec</td></tr><tr><td class=tlgrey>VRAM</td><td align=center valign=middle>16GB<br>32GB</td><td align=center valign=middle>16GB<br>32GB</td><td align=center valign=middle>12GB</td><td align=center valign=middle>16GB</td></tr><tr><td class=tlgrey>L2 Cache</td><td align=center valign=middle>6MB</td><td align=center valign=middle>6MB</td><td align=center valign=middle>4.5MB</td><td align=center valign=middle>4MB</td></tr><tr><td class=tlgrey>Half Precision</td><td align=center valign=middle>30 TFLOPS</td><td align=center valign=middle>28 TFLOPS</td><td align=center valign=middle>27.6 TFLOPS</td><td align=center valign=middle>21.2 TFLOPS</td></tr><tr><td class=tlgrey>Single Precision</td><td align=center valign=middle>15 TFLOPS</td><td align=center valign=middle>14 TFLOPS</td><td align=center valign=middle>13.8 TFLOPS</td><td align=center valign=middle>10.6 TFLOPS</td></tr><tr><td class=tlgrey>Double Precision</td><td align=center valign=middle>7.5 TFLOPS</td><td align=center valign=middle>7 TFLOPS</td><td align=center valign=middle>6.9 TFLOPS</td><td align=center valign=middle>5.3 TFLOPS</td></tr><tr readability=2><td class=tlgrey>Tensor Performance<br>(Deep Learning)</td><td align=center valign=middle>120 TFLOPS</td><td align=center valign=middle>112 TFLOPS</td><td align=center valign=middle>110 TFLOPS</td><td align=center valign=middle>N/A</td></tr><tr><td class=tlgrey>GPU</td><td align=center valign=middle>GV100</td><td align=center valign=middle>GV100</td><td align=center valign=middle>GV100</td><td align=center valign=middle>GP100</td></tr><tr><td class=tlgrey>Transistor Count</td><td align=center valign=middle>21B</td><td align=center valign=middle>21B</td><td align=center valign=middle>21.1B</td><td align=center valign=middle>15.3B</td></tr><tr><td class=tlgrey>TDP</td><td align=center valign=middle>300W</td><td align=center valign=middle>250W</td><td align=center valign=middle>250W</td><td align=center valign=middle>300W</td></tr><tr><td class=tlgrey>Form Factor</td><td align=center valign=middle>Mezzanine (SXM2)</td><td align=center valign=middle>PCIe</td><td align=center valign=middle>PCIe</td><td align=center valign=middle>Mezzanine (SXM2)</td></tr><tr><td class=tlgrey>Cooling</td><td align=center valign=middle>Passive</td><td align=center valign=middle>Passive</td><td align=center valign=middle>Active</td><td align=center valign=middle>Passive</td></tr><tr><td class=tlgrey>Manufacturing Process</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 16nm FinFET</td></tr><tr><td class=tlgrey>Architecture</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Pascal</td></tr></tbody></table><p>But whatever the internal rationale and timetable on NVIDIA’s part, the end result is that at least for the foreseeable future, NVIDIA is going to be offering multiple V100 capacities across its lineup, including both the SXM2 and PCIe form factors. For NVIDIA's customers then, they now have a choice to make on capacity. The larger version is clocked identically to its 16GB counterpart, so it doesn't have an immediate performance advantage outside of memory capacity. However in cases where a dataset that doesn't fit in the 16GB model fits in the 32GB model, the performance differences can be very significant due to the large impact of memory thrashing; NVIDIA is advertising a 50% performance boost in some memory-limited HPC applications thanks to the larger RAM pool.</p><p>Finally, the company also confirmed that these cards will be priced differently. However they aren’t sharing the list prices for the parts, so it’s not clear whether the new pricing structure gives the 16GB model a price cut, or if the 32GB model is being offered at a price premium.</p><p>Source: NVIDIA</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH5zhI9yZmpul5d6r8LInaCaZaSawK2tjK9oaWhdnLK1v4yrnKmqmZrDpnnRnqSaoZ6oeqq6jKmpqJylmMGqu80%3D</p></section></article></main></div><footer><div class=container><span class=copyright>&copy; 2024 BlinkVib - <a rel=license href=http://creativecommons.org/licenses/by/4.0/>CC BY 4.0</a></span></div></footer><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>